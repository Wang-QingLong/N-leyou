Lucene&Solr&ElasticSearch-面试题

1、Lucene和Solr和Elasticsearch的区别

Lucene是apache下的一个子项目，是一个开放源代码的全文检索引擎工具包，但它不是一个完整的全文检索引擎，而是一个全文检索引擎的架构，提供了完整的查询引擎和索引引擎，部分文本分析引擎。官网地址：https://lucene.apache.org/

Solr

Solr是一个高性能，采用Java5开发，基于Lucene的全文搜索服务器。同时对其进行了扩展，提供了比Lucene更为丰富的查询语言，同时实现了可配置、可扩展并对查询性能进行了优化，并且提供了一个完善的功能管理界面，是一款非常优秀的全文搜索引擎。官网地址：http://lucene.apache.org/solr/


Elasticsearch

Elasticsearch跟Solr一样，也是一个基于Lucene的搜索服务器，它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。
————————————————
1、Elasticsearch的优缺点：
优点：

1.Elasticsearch是分布式的。不需要其他组件，分发是实时的，被叫做”Push replication”。

2.Elasticsearch 完全支持 Apache Lucene 的接近实时的搜索。

3.处理多租户（multitenancy）不需要特殊配置，而Solr则需要更多的高级设置。

4.Elasticsearch 采用 Gateway 的概念，使得完备份更加简单。

5.各节点组成对等的网络结构，某些节点出现故障时会自动分配其他节点代替其进行工作。

缺点：

1.只有一名开发者（当前Elasticsearch GitHub组织已经不只如此，已经有了相当活跃的维护者）

2.还不够自动（不适合当前新的Index Warmup API）
——————————————
Solr的优缺点：
优点

1.Solr有一个更大、更成熟的用户、开发和贡献者社区。

2.支持添加多种格式的索引，如：HTML、PDF、微软 Office 系列软件格式以及 JSON、XML、CSV 等纯文本格式。

3.Solr比较成熟、稳定。

4.不考虑建索引的同时进行搜索，速度更快。

缺点

1.建立索引时，搜索效率下降，实时索引搜索效率不高。
————————————————
Elasticsearch 与 Solr 的比较：

1.二者安装都很简单；

2.Solr 利用 Zookeeper 进行分布式管理，而 Elasticsearch 自身带有分布式协调管理功能;

3.Solr 支持更多格式的数据，而 Elasticsearch 仅支持json文件格式；

4.Solr 官方提供的功能更多，而 Elasticsearch 本身更注重于核心功能，高级功能多有第三方插件提供；

5.Solr 在传统的搜索应用中表现好于 Elasticsearch，但在处理实时搜索应用时效率明显低于 Elasticsearch。

6.Solr 是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。
————————————————


elasticsearch了解多少，说说你们公司es的集群架构，索引数据大小，分片有多少，以及一些调优手段 。
面试官：想了解应聘者之前公司接触的ES使用场景、规模，有没有做过比较大规模的索引设计、规划、调优。

解答：

如实结合自己的实践场景回答即可。

比如：ES集群架构13个节点，索引根据通道不同共20+索引，根据日期，每日递增20+，索引：10分片，每日递增1亿+数据，

每个通道每天索引大小控制：150GB之内。



仅索引层面调优手段：

1.1、设计阶段调优

1）根据业务增量需求，采取基于日期模板创建索引，通过roll over API滚动索引；

2）使用别名进行索引管理；

3）每天凌晨定时对索引做force_merge操作，以释放空间；

4）采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储；

5）采取curator进行索引的生命周期管理；

6）仅针对需要分词的字段，合理的设置分词器；

7）Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。 …



1.2、写入调优

1）写入前副本数设置为0；

2）写入前关闭refresh_interval设置为-1，禁用刷新机制；

3）写入过程中：采取bulk批量写入；

4）写入后恢复副本数和刷新间隔；

5）尽量使用自动生成的id。



1.3、查询调优

1）禁用wildcard；

2）禁用批量terms（成百上千的场景）；

3）充分利用倒排索引机制，能keyword类型尽量keyword；

4）数据量大时候，可以先基于时间敲定索引再检索；

5）设置合理的路由机制。



1.4、其他调优

部署调优，业务调优等。

上面的提及一部分，面试者就基本对你之前的实践或者运维经验有所评估了。



2、elasticsearch的倒排索引是什么？
面试官：想了解你对基础概念的认知。

解答：通俗解释一下就可以。

传统的我们的检索是通过文章，逐个遍历找到对应关键词的位置。

而倒排索引，是通过分词策略，形成了词和文章的映射关系表，这种词典+映射表即为倒排索引。

有了倒排索引，就能实现o（1）时间复杂度的效率检索文章了，极大的提高了检索效率。



学术的解答方式：

倒排索引，相反于一篇文章包含了哪些词，它从词出发，记载了这个词在哪些文档中出现过，由两部分组成——词典和倒排表。

加分项：倒排索引的底层实现是基于：FST（Finite State Transducer）数据结构。

lucene从4+版本后开始大量使用的数据结构是FST。FST有两个优点：

1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；

2）查询速度快。O(len(str))的查询时间复杂度。



3、elasticsearch 索引数据多了怎么办，如何调优，部署？
面试官：想了解大数据量的运维能力。

解答：索引数据的规划，应在前期做好规划，正所谓“设计先行，编码在后”，这样才能有效的避免突如其来的数据激增导致集群处理能力不足引发的线上客户检索或者其他业务受到影响。

如何调优，正如问题1所说，这里细化一下：

3.1 动态索引层面

基于模板+时间+rollover api滚动创建索引，举例：设计阶段定义：blog索引的模板格式为：blog_index_时间戳的形式，每天递增数据。

这样做的好处：不至于数据量激增导致单个索引数据量非常大，接近于上线2的32次幂-1，索引存储达到了TB+甚至更大。

一旦单个索引很大，存储等各种风险也随之而来，所以要提前考虑+及早避免。

3.2 存储层面

冷热数据分离存储，热数据（比如最近3天或者一周的数据），其余为冷数据。

对于冷数据不会再写入新数据，可以考虑定期force_merge加shrink压缩操作，节省存储空间和检索效率。

3.3 部署层面

一旦之前没有规划，这里就属于应急策略。

结合ES自身的支持动态扩展的特点，动态新增机器的方式可以缓解集群压力，注意：如果之前主节点等规划合理，不需要重启集群也能完成动态新增的。



4、elasticsearch是如何实现master选举的？
面试官：想了解ES集群的底层原理，不再只关注业务层面了。

解答：

前置前提：

1）只有候选主节点（master：true）的节点才能成为主节点。

2）最小主节点数（min_master_nodes）的目的是防止脑裂。

这个我看了各种网上分析的版本和源码分析的书籍，云里雾里。

核对了一下代码，核心入口为findMaster，选择主节点成功返回对应Master，否则返回null。选举流程大致描述如下：

第一步：确认候选主节点数达标，elasticsearch.yml设置的值discovery.zen.minimum_master_nodes；

第二步：比较：先判定是否具备master资格，具备候选主节点资格的优先返回；若两节点都为候选主节点，则id小的值会主节点。注意这里的id为string类型。

题外话：获取节点id的方法。

1、GET /_cat/nodes?v&h=ip,port,heapPercent,heapMax,id,name

2、ip        port heapPercent heapMax id  name

3、127.0.0.1 9300          39  1.9gb Hk9w Hk9wFwU



5、详细描述一下Elasticsearch索引文档的过程？
面试官：想了解ES的底层原理，不再只关注业务层面了。

解答：

这里的索引文档应该理解为文档写入ES，创建索引的过程。

文档写入包含：单文档写入和批量bulk写入，这里只解释一下：单文档写入流程。

记住官方文档中的这个图。

第一步：客户写集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演路由节点的角色。）

第二步：节点1接受到请求后，使用文档_id来确定文档属于分片0。请求会被转到另外的节点，假定节点3。因此分片0的主分片分配到节点3上。

第三步：节点3在主分片上执行写操作，如果成功，则将请求并行转发到节点1和节点2的副本分片上，等待结果返回。所有的副本分片都报告成功，节点3将向协调节点（节点1）报告成功，节点1向请求客户端报告写入成功。

如果面试官再问：第二步中的文档获取分片的过程？

回答：借助路由算法获取，路由算法就是根据路由和文档id计算目标的分片id的过程。

shard = hash(_routing) % (num_of_primary_shards)



6、详细描述一下Elasticsearch搜索的过程？
面试官：想了解ES搜索的底层原理，不再只关注业务层面了。

解答：

搜索拆解为“query then fetch” 两个阶段。

query阶段的目的：定位到位置，但不取。

步骤拆解如下：

1）假设一个索引数据有5主+1副本 共10分片，一次请求会命中（主或者副本分片中）的一个。

2）每个分片在本地进行查询，结果返回到本地有序的优先队列中。

3）第2）步骤的结果发送到协调节点，协调节点产生一个全局的排序列表。

fetch阶段的目的：取数据。

路由节点获取所有文档，返回给客户端。



7、Elasticsearch在部署时，对Linux的设置有哪些优化方法？
面试官：想了解对ES集群的运维能力。

解答：

1）关闭缓存swap;

2）堆内存设置为：Min（节点内存/2, 32GB）;

3)设置最大文件句柄数；

4）线程池+队列大小根据业务需要做调整；

5）磁盘存储raid方式——存储有条件使用RAID10，增加单节点性能以及避免单节点存储故障。



8、lucence内部结构是什么？
面试官：想了解你的知识面的广度和深度。

解答：

Lucene是有索引和搜索的两个过程，包含索引创建，索引，搜索三个要点。可以基于这个脉络展开一些。




redis的五种数据类型以及它的应用场景：

String  缓存，限速(保护短信接口防刷)，共享session
hash哈希  用户信息管理，因为hash对字符串序列化信息更加直观，所以在更新操作上面更加直观
列表     消息队列    lpush  lpop
set集合  无序 不能通过索引下标获取元素，除了支持crud还支持取集合交集，并集，差集
         使用场景:标签 比如一个用户对新闻体育感兴趣，而另外一个用户对音乐，游戏感兴趣，这些数         据就是标签，

list集合 保留了集合当中不可以重复的特性，但是不同的是它支持排序，它和列表的使用索引下标作为排序
         依据不同的是，它给每一个元素设置了一个分数，作为排序的依据(元素不可以重复但是分数可以)
         使用场景:  排行榜


项目出现生产问题，排查日志有什么方法？

1，问题排查，优先逐个看日志，日志哪里错了就看哪里，
2，数据对象封装和解析问题，内部设计不要嵌套太深。
3，配置文件信息，其中很多信息在开发环境，测试环境，生产环境的配置值是不一样的，开发和测试环境可能一样，但生产环境肯定不一样；
4，程序设计应注意，层次分明：请求层，业务层，DB模型层，相关安全权限日志等控制辅助层；功能应分解为各个相对独立解耦的小单元，一个模块应由各小单元功能组合而成，各关键之处可打印日志，异常时日志打印必要的入参，返回数据，异常信息等，以便生产环境根据日志排查问题；

我们一般会采用排除法，从外部排查到内部排查的方式来定位线上服务问题。

首先我们要排除其他进程 (除主进程之外) 可能引起的故障问题；

然后排除业务应用可能引起的故障问题；

可以考虑是否为运营商或者云服务提供商所引起的故障。







java的object基类公用方法详解
原创喜欢多瑞咪的发索拉西 发布于2018-04-12 21:56:33 阅读数 1330  收藏
展开
入行许久，对于java一些基础知识开始做点总结。首先从我们最开始入门的object类开始。

这个类是java体系的最元老级别的类，也一定程度上承载着java这门从编程语言的精髓思想。

Object类

组成如下：



由图可知，object类除去object()之外，有11个成员方法。object()是构造方法。

下面来回顾下object类的方法的作用。

注：由于某些方法的作用是相辅相成，关系密切的，所以可能会放在一起讲解。

1、clone()方法

这个方法是为object的克隆对象的而生。有些人可能会不明白，克隆不就是copy吗？copy不就是跟new一个对象差不多嘛？

其实不然，clone（）方法存在的意义在于java语言的对象引用机制。

如：

Person p1 = new Person();

Person p2 = p1;

此时，p1和p2是引用的同一个对象的，这个对象是在jvm的堆内存中共享的。也就睡说。如果p2被一系列操作改变了它本身的属性值，那么p1也会跟着改变，至始至终，p1和p2引用的是同一个东西。

那么要避免p1跟着p2发生变动，应该怎么做呢？

那就是可以使用到clone()方法了。使用这个方法可以在堆中克隆出另一个对象，这样一来，p2变动，p1就不会变了，因为他们引用的不再是同给一个对象。

clone方法的使用上，要注意，首先要实现Cloneable的接口，然后在类中重写Object类中的clone方法，具体过程可以自行研究，不做赘述。



2、equal()和hashCode()方法

这两个方法是面试经典。也是比较重点要掌握的方法。毕竟做java的，对equal（）不可能不熟悉。

在Java中，有时候要判断两个对象之间的想的相等关系，并不是想象中那么容易的。因为我们无法通过代数中的"="或者"=="来粗暴的断定。

"=="只是比较两个对象的地址是否一致，当然，如果返回true，那说明这两个对象确实是相等的。因为每个对象在内存中都是有着不同的

存放地址，地址相同自然就是同一个对象了。但大部分时候，我们所谓的比较两个对象是否相等时，并不是将引用同一个对象的引用来比

较的。就比如，随便new 两个对象进行比较，这就要注意了，因为两个都是新生成的对象，内存地址肯定是不一样的，这个时候再用"=="比

较，肯定个不可能返回true（前提是没有重写hashcode()和equal()），有人会说了，既然不返回true，那是不是就说明这两个对象不相等？

事实上，并非如此。比如，你身上有一百块钱，我身上也有一百块钱，显然这两张一百块钱不是同一回事儿。但是不是相等的呢？

显然是的。

因为我们所谓的相等，是从价值上来比较的，同样是一百块钱 ，能买的东西是一样的多，自然是相等的。

可见，程序里面的对象是否相等，并不是但从地址是否一致来考量的，还要从程序员的比较和考量的的角度（比较，比较两百块钱是比较价值，

而并非比较新旧程度）来定的。

那么说了这么多，终于要进入正题了。

hashcode（）方法其实就是对应对象的地址，调用它的时候，它的返回值就是对象的地址。

equal（）方法则是比较两个对象的具体方法描述，或者说规则。也就是说，你要比较两个对象是否相等。你的比较原则是什么，怎么去比较，

就重写在equal（）方法中。

此方法在默认情况下也是"=="，有兴趣的童鞋可以去看源码，非常简单。

由于这两个方法是面试的重点，我希望大家都可以很好的理解。大家可以好好去研究下hashset（）实现比较的原理来帮助理解，这个网上有很

多资料，大家可以自行去研究。

还有一点，大家需要注意的是，一般情况下，如果要比较两个对象是否相等，直接用equal()就可以了，之所以还要有hashcode(),是出于效率来

考虑，毕竟如果hashcode（）方法返回为false的话，也就不会需简要去比较equal（）了。

3、finalize()

这个方法是专供垃圾回收提供的，垃圾回收期跳如果要针对一个类的对象进行回收，那么它会先调用finalize()方法，但要注意，并非调用了

finalize（）,就马上会

回收。java的垃圾回收机制是无法认为预测的，它只在jvm认为合适的时候才会进行回收。而所谓的合适，唯一的判断标准就是内存不足。

4、getClass（）

此方法与反射有关。用于返回一个返回该对象的运行时类的java.lang.Class对象。也就是运行中的对象本身。

5、notify、notifiAll和wait()

对多线程熟悉的童鞋应该比较清楚这三个方法。这三个方法是相辅相成来实现多线程的。

wait()来阻塞线程，wait（）被调用后，线程将会进行等待状态，锁被释放，同时线程也会让出cpu资源，其他的线程可以运行。

notify\notifyAll方法用于唤醒线程，调用notify\notifyAll方法后，不会立即释放锁，而是等待sychronize代码块执行完后。或者遇到

wait（）方法后，在释放锁。因此，有一点要非常注意，notify、notifiAll和wait()是必须在sychronize包含的代码快中使用。这跟thread

类的sleep方法是不一致的，sleep（）方法可以在任意地

方使用。

6、toString（）

toString()方法就更不用多说了，很多时候我们会在类里面重写这个方法。它默认的作用是就对象转化为字符串的形式。如果是基础数据类型，

如int ，long，byte等等，但如是引用对象，toString（）将会转化为该对象的内存地址。









